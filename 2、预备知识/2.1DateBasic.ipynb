{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 数据处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**此处为torch,~~虽然包叫pytorch~~**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量：数组，但里面的内容都是数值，维度不限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`shape`可以查询张量的形状;[]代表维度为1，12代表这一维度的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numel()`可以访问张量中元素的总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`reshape(c,r)`,可以将张量重新排列成多维形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 4]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m y\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[4, 4]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "y = x.reshape(4, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但重组时，col*row必须等于元素总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]]) \n",
      " tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros((2, 3, 4))\n",
    "o = torch.ones((3, 2, 4))\n",
    "print(z, '\\n' ,o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`zeros()`构造全0矩阵，同理`ones()`, ~~没有除了1和0之外的数~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1,  2,  3,  4],\n        [ 5,  6,  7,  8],\n        [ 9, 10, 11, 12]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`tensor()`手动构造变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2559,  0.4066,  0.4201, -1.1634],\n        [-2.0670,  0.6678,  0.9912,  0.2923],\n        [ 0.2710,  1.9265, -1.6423, -0.9642]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "生成随机数张量，元素平均数为0，标准差为1的正态分布中随机采样"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 运算符"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 3.,  5.,  8., 13.]),\n tensor([-1., -1.,  0.,  3.]),\n tensor([ 2.,  6., 16., 40.]),\n tensor([0.5000, 0.6667, 1.0000, 1.6000]),\n tensor([1.0000e+00, 8.0000e+00, 2.5600e+02, 3.2768e+04]),\n tensor([1., 2., 0., 3.]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0,2, 4, 8])\n",
    "y = torch.tensor([2,  3, 4, 5])\n",
    "x+y,x-y,x*y,x/y,x**y,x%y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "对于相同形状的张量，可以通过(+,-,*,/,%)作运算，具体来说：$I+J \\rightarrow I_i+J_i$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([15.1543,  2.0000,  2.7183, 15.1543], dtype=torch.float64)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "x = torch.tensor([numpy.e,numpy.log(2),1,torch.e])\n",
    "torch.exp(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "exp()求解e的x次方：$y_i=e^{x_i}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11],\n         [ 2,  1,  4,  3],\n         [ 1,  2,  3,  4],\n         [ 4,  3,  2,  1]]),\n tensor([[ 0,  1,  2,  3,  2,  1,  4,  3],\n         [ 4,  5,  6,  7,  1,  2,  3,  4],\n         [ 8,  9, 10, 11,  4,  3,  2,  1]]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "y = torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "torch.cat((x,y),dim=0), torch.cat((x,y),dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过`cat()`可以实现拼接，`dim=0`按照行，`dim=1`按列"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 4 but got size 3 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m12\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m      2\u001B[0m y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m4\u001B[39m],[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m],[\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m2\u001B[39m]])\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m, torch\u001B[38;5;241m.\u001B[39mcat((x,y),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 0. Expected size 4 but got size 3 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "y = torch.tensor([[2,1,4],[1,2,3],[4,3,2]])\n",
    "torch.cat((x,y),dim=0), torch.cat((x,y),dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "若尺寸不对应则会报错"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[False,  True, False,  True],\n        [False, False, False, False],\n        [False, False, False, False]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "y = torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "x == y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "近似于求位与运算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(66), tensor(66))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "torch.sum(x), x.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "元素求和"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 1],\n        [1, 2],\n        [2, 3]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a + b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "广播机制"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[1],\n          [1],\n          [1]],\n \n         [[2],\n          [3],\n          [4]]]),\n tensor([[[1, 2, 3]]]),\n tensor([[[2, 3, 4],\n          [2, 3, 4],\n          [2, 3, 4]],\n \n         [[3, 4, 5],\n          [4, 5, 6],\n          [5, 6, 7]]]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([ [ [1],[1],[1] ] ,[[2],[3],[4] ] ])\n",
    "y = torch.tensor([ [ [1,2,3]] ])\n",
    "x,y,x+y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "试试多维，有点废脑子"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]]),\n tensor([ 8,  9, 10, 11]),\n tensor([ 8,  9, 10, 11]),\n tensor([[0, 1, 2, 3],\n         [4, 5, 6, 7]]),\n tensor([[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]]),\n tensor([[0, 1, 2, 3],\n         [4, 5, 6, 7]]),\n tensor([[0, 1, 2, 3],\n         [4, 5, 6, 7]]),\n tensor([[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]]),\n tensor([], size=(0, 4), dtype=torch.int64))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "x,x[-1],x[2],x[0:2],x[0:3],x[0:-1],x[:-1],x[:],x[:0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "按行切片"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1, 5, 9]),\n tensor([[ 5,  6,  7],\n         [ 9, 10, 11]]),\n tensor([[ 1,  3],\n         [ 9, 11]]),\n tensor([[ 0,  2],\n         [ 8, 10]]))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).reshape((3,4))\n",
    "x[:,1] , x[1:3,1:] , x[0::2,1::2], x[0::2,0::2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`a:b:c`,在区间[a,b)中取数，step=c,a,c默认为0，b默认最后一位"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  9,  7],\n        [ 8,  9, 10, 11]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1, 2] = 9\n",
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "暴力写入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(4)\n",
    "before = id(y)\n",
    "y = y + x\n",
    "id(y) == before"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在处理变量中，一般操作会导致新建内存，如果矩阵数据特别大，容易消耗内存,可以使用原地存储"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [4] doesn't match the broadcast shape [3, 4]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m      2\u001B[0m before \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mid\u001B[39m(y)\n\u001B[0;32m----> 3\u001B[0m y \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m x\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mid\u001B[39m(y) \u001B[38;5;241m==\u001B[39m before\n",
      "\u001B[0;31mRuntimeError\u001B[0m: output with shape [4] doesn't match the broadcast shape [3, 4]"
     ]
    }
   ],
   "source": [
    "y = torch.arange(4)\n",
    "before = id(y)\n",
    "y += x\n",
    "id(y) == before"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(z): 140157950377472\n",
      "id(z): 140157950377472\n"
     ]
    }
   ],
   "source": [
    "y = torch.arange(4)\n",
    "x = torch.arange(4,8,1)\n",
    "z = torch.zeros_like(y)\n",
    "print('id(z):',id(z))\n",
    "z[:] = x + y\n",
    "print('id(z):',id(z))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pytorch与Numpy的互换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(numpy.ndarray, torch.Tensor)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = x.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A),type(B)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "将大小为1的张量转化为python标量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([3.5000]), 3.5, 3.5, 3)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a,a.item(),float(a),int(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
