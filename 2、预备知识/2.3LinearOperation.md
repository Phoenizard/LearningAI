## 2.3 线性代数


```python
import torch
```

### 2.3.1 标量

虽然直接声明常量更为常见，但是`torch`也支持创建标量，即长度为1的一维张量


```python
x = torch.tensor(3.0)
y = torch.tensor(2.0)
```

### 2.3.2 向量

#### 向量的声明

向量的声明通常就是一维张量，即`tensor([x,y,z,...])`


```python
x = torch.arange(4,dtype=torch.float32)
x
```




    tensor([0., 1., 2., 3.])



#### 向量的形状

shape可以查看向量的维度，是一个元素组


```python
y = torch.arange(12).reshape(2, 3, 2)
y, y.shape
```




    (tensor([[[ 0,  1],
              [ 2,  3],
              [ 4,  5]],
     
             [[ 6,  7],
              [ 8,  9],
              [10, 11]]]),
     torch.Size([2, 3, 2]))



### 矩阵

一个二维张量,$R^(M·N)$ 对应A(m,n)


```python
A = torch.arange(20, dtype=torch.float32).reshape(5, 4)
A
```




    tensor([[ 0.,  1.,  2.,  3.],
            [ 4.,  5.,  6.,  7.],
            [ 8.,  9., 10., 11.],
            [12., 13., 14., 15.],
            [16., 17., 18., 19.]])



矩阵的转制 `A.T`


```python
A.T
```




    tensor([[ 0.,  4.,  8., 12., 16.],
            [ 1.,  5.,  9., 13., 17.],
            [ 2.,  6., 10., 14., 18.],
            [ 3.,  7., 11., 15., 19.]])



矩阵按元素相乘，$Hadamard Product


```python
B = A.clone()
A * B
```




    tensor([[  0.,   1.,   4.,   9.],
            [ 16.,  25.,  36.,  49.],
            [ 64.,  81., 100., 121.],
            [144., 169., 196., 225.],
            [256., 289., 324., 361.]])



矩阵的按列降维和按行降维


```python
A_sum_axis0 = A.sum(axis=0)
A_sum_axis1 = A.sum(axis=1)
print(A_sum_axis0, A_sum_axis0.shape)
print(A_sum_axis1, A_sum_axis1.shape)
```

    tensor([40., 45., 50., 55.]) torch.Size([4])
    tensor([ 6., 22., 38., 54., 70.]) torch.Size([5])


求平均值，按平均值降维，矩阵数据必须是`dtype=torch.float32`


```python
A.mean(), A.mean(axis=0), A.mean(axis=1)
```




    (tensor(9.5000),
     tensor([ 8.,  9., 10., 11.]),
     tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000]))



非均值降维


```python
sum_A = A.sum(axis=1,keepdim=True)
A, sum_A, A/sum_A
```




    (tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.],
             [12., 13., 14., 15.],
             [16., 17., 18., 19.]]),
     tensor([[ 6.],
             [22.],
             [38.],
             [54.],
             [70.]]),
     tensor([[0.0000, 0.1667, 0.3333, 0.5000],
             [0.1818, 0.2273, 0.2727, 0.3182],
             [0.2105, 0.2368, 0.2632, 0.2895],
             [0.2222, 0.2407, 0.2593, 0.2778],
             [0.2286, 0.2429, 0.2571, 0.2714]]))



按列、行累加


```python
A, A.cumsum(axis=0), A.cumsum(axis=1)
```




    (tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.],
             [12., 13., 14., 15.],
             [16., 17., 18., 19.]]),
     tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  6.,  8., 10.],
             [12., 15., 18., 21.],
             [24., 28., 32., 36.],
             [40., 45., 50., 55.]]),
     tensor([[ 0.,  1.,  3.,  6.],
             [ 4.,  9., 15., 22.],
             [ 8., 17., 27., 38.],
             [12., 25., 39., 54.],
             [16., 33., 51., 70.]]))



#### 点乘与乘法

点乘等价于每个元素相乘并求和


```python
y = torch.ones(4, dtype=torch.float32)
print(torch.dot(x, y))
print(torch.sum(x * y))
```

    tensor(6.)
    tensor(6.)


矩阵-向量


```python
torch.mv(A, x)
```




    tensor([ 14.,  38.,  62.,  86., 110.])



矩阵-矩阵


```python
B = torch.ones(4, 3)
torch.mm(A, B)
```




    tensor([[ 6.,  6.,  6.],
            [22., 22., 22.],
            [38., 38., 38.],
            [54., 54., 54.],
            [70., 70., 70.]])



### 范数

L1范数的定义：
$$||x||_1 = \sum_{i=1}^{n}{|x_i|}$$


```python
u = torch.tensor([3., 4., 12.])
torch.abs(u).sum()
```




    tensor(19.)



L2范数的定义：
$$norm = ||x||_2 = \sqrt{\sum_{i=1}^{n}{x_i^2}}$$


```python
torch.norm(u)
```




    tensor(13.)


